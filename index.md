---
layout: default
---

<!-- Text can be **bold**, _italic_, or ~~strikethrough~~. -->

<!-- [Link to another page](./another-page.html). -->

<!-- There should be whitespace between paragraphs. -->

This website has been developed as part of the final project for CS 7641: Machine Learning (Spring 2024) at Georgia Tech. Our team consists of:
1. Divij Mishra
2. Karan Nahar
3. Parth Athale
4. Priyanka Singh
5. Vamsi Kalidindi

## Table of Contents

1. [Introduction/Background](#introduction/background)
2. [Problem Definition](#problem-definition)
3. [Methods](#methods)
4. [Potential Results](#potential-results)
5. [References](#references)
6. [Gantt Chart](#gantt-chart)
7. [Contribution Table](#contribution-table)

## Introduction/Background
Our project aims to tackle the issue of AI-based fake news generation by training models to classify a given article as human-written or machine-generated. 

Previous work indicates that it is difficult for humans to distinguish between human-written news and GPT-3 news, highlighting the importance of fake news detection systems [3]. However, it is not clear whether larger models will necessarily be better at discriminating between the two types of news. [1] indicates that language models which are good at generating fake news are the best at detecting fake news, which leads us to believe LLMs would perform well at this task. Surprisingly, [2] observed that Transformer-based models may not generalize well, while traditional models may generalize better and provide an understanding of which features are important. 

The dataset we plan to use was used to develop the GROVER model [1], which can generate fake news as well as detect fake news generated by AI. The dataset comprises headlines and article texts with a label indicating whether they are real or fake.

## Problem Definition
Using the GROVER dataset, we plan to both fine-tune a Large Language Model (LLM) and train a smaller traditional ML model to classify news articles into machine-generated and human-written.

## Methods
1. We wish to fine-tune an LLM for classification on the GROVER dataset. We have tentatively chosen OpenLLaMA â€“ 7B as our model. We have access to the 16GB Nvidia Tesla T4 GPU via Google Colab Pro. It is feasible to fine-tune a 7B LLM on such hardware using QLoRA for compression and approximate fine-tuning. 
2. We aim to train a smaller classification model on the same dataset. We plan to use TF-IDF for feature generation, PCA for dimensionality reduction, and XGBoost for classification. 
3. If we have sufficient time, we plan to use topic modeling and clustering techniques, based on the BERTopic pipeline, to cluster articles in the GROVER dataset based on news topics. Based on this, we aim to analyze whether machine-generated news might be easier to detect in certain domains over others. 
4. Since the GROVER dataset consists of mostly text data, we would likely need multiple preprocessing techniques to perform TF-IDF. We plan to use spaCy for tokenization, stop-word removal, and lemmatization. 

## Potential Results
Our project goals are to train reliable discriminative classifiers to identify machine-generated news articles. As our problem is a classification problem, we would like to compare our classifiers on the following metrics: accuracy, precision, recall, F1-score. After topic modeling and clustering, we will have a topic-label associated with each article. As such, we will also compare category-wise precision, recall, and macro-averaged F1-score. 

We expect to be able to quantify the improvement in fake news classification using an LLM and provide a low-resource technique for fake news detection. 

## References
1. Zellers, R., Holtzman, A., Rashkin, H., Bisk, Y., Farhadi, A., Roesner, F., & Choi, Y. (2019). Defending Against Neural Fake News. ArXiv. /abs/1905.12616 
2. Iceland, M. (2023). How Good Are SOTA Fake News Detectors. ArXiv. /abs/2308.02727  
3. Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., ... & Amodei, D. (2020). Language models are few-shot learners. Advances in neural information processing systems, 33, 1877-1901. 

## Gantt Chart

[Gantt Chart](https://gtvault-my.sharepoint.com/:x:/g/personal/dmishra45_gatech_edu/ETxFnZOXn3JBk6j6xNu7_PwBAAGmj1Igddgi3tMxG-g3pw){:target="blank"}

## Contribution Table

| Name | Contribution |
|----------|----------|
| Vamsi Kalidindi | Introduction & Problem Statement | 
| Divij Mishra | Methods | 
| Karan Nahar | Potential Dataset & Timeline |
| Parth Athale | Github Page |
| Priyanka Singh | Potential Results |
